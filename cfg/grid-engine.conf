################################################################## 
# smartmet-engine-grid
################################################################## 

# This is a configuration file used by the module
# smartmet-engine-grid. The SmartMet server's configuration
# file for the "grid" engine should point to this file.

##################################################################



# Importing global configuration parameters. There should be
# an environment variable SMARTMET_ENV_FILE that points to
# the global configuration file. The idea is that you can easily
# change your environment by editing this file. 

@ifdef SMARTMET_ENV_FILE
  @include "$(SMARTMET_ENV_FILE)"
@else
  @print "The environment variable 'SMARTMET_ENV_FILE' not defined!" @location
  @include "$(HOME)/workspace/smartmet-tools-grid/cfg/smartmet-dev-env.cfg"
@endif


smartmet :
{
library :
{

grid-files :
{
  # Processing of grid/grib files requires a lot of configuration information. 
  # This information should be found from the file below. 

  configFile = "$(GRID_FILES_LIBRARY_CONFIG_FILE)"
  
  # Are we using our own memoryMapper implementation. If "premapEnabled" is "true" then
  # the whole grid is preloaded when it is first time accessed. Otherwise only the requested
  # memory page is mapped. The point is that we can load data in small pieces when it requsted
  # or bigger pieces so that the number of the download requests will be smaller. 
  
  memoryMapper :
  {
    enabled = true
    accessFile = "%(DIR)/access.csv"
    premapEnabled = true
    maxProsessingThreads = 30
    maxMessages = 100000
    pageCacheSize = 2000000
    fileHandleLimit = 10000    
  }

  # If the data server is local then the grid file cache can be used to improve
  # performance. This cache is used caching uncompressed grid data. When the cache 
  # is full then the oldest data is automatically removed. The cache type can be
  # "memory" or "filesys". If the type is "filesys" then cached grids are stored
  # into files and these files are memory mapped. 
    
  cache :
  {
    type                = "filesys"
    directory           = "$(HOME)/Disk/Cache"
    numOfGrids          = 50000
    maxSizeInMegaBytes  = 30000   
  }
}

} # library


engine :
{
grid :
{

  # The usage of the grid-engine can be enabled/disabled
  
  enabled = true

# The content server defines the source of the content information. Usually the master 
# content source is the Redis database. However,it can be also a memory-based content
# server or a caching content server, which are accessed by HTTP or CORBA.

# The Redis database is not usually fast enough for our searching purposes. That's why 
# its information is usally cached locally into the memory. In this case the content 
# information can be sorted so that it can be fetched very fast. In spite of that we
# can sort the current content information in many ways, we should not sort it all
# possible ways because this increases the memory consumtion and it also makes content
# updates slower. In practice, we should select the main content identifiers and sort
# the content information according to them. All the other information should be mapped
# to those identifiers when querying content information.

# If the content source itself is a caching content server then there is usually no need to 
# locally cache the same information. Caching content information makes content searching very 
# fast but it might required a lot of memory. That's why it usually makes sense to use a remote 
# caching server if that is possible. On the other hand this means that the grid engine can start 
# much faster because it does not need to cache content information first.

content-server :
{
    
  content-source : 
  {
    # Content source type (redis/corba/http/file/postgresql)

    type = "redis"

    redis :
    {
      address          = "$(REDIS_CONTENT_SERVER_PRIMARY_ADDRESS)"
      port             = $(REDIS_CONTENT_SERVER_PRIMARY_PORT)
      tablePrefix      = "$(REDIS_CONTENT_SERVER_TABLE_PREFIX)"
      secondaryAddress = "$(REDIS_CONTENT_SERVER_SECONDARY_ADDRESS)"
      secondaryPort    = $(REDIS_CONTENT_SERVER_SECONDARY_PORT)
      lockEnabled      = false;
      reloadRequired   = false;
    }

    
    postgresql :
    {
      primaryConnectionString = "$(PG_CONTENT_SERVER_PRIMARY_CONNECTION_STRING)"
      secondaryConnectionString = "$(PG_CONTENT_SERVER_SECONDARY_CONNECTION_STRING)"
    }    
    
    corba :
    {
      ior          = "$(CORBA_CONTENT_SERVER_IOR)"
    }


    http :
    {
      url          = "$(HTTP_CONTENT_SERVER_URL)"
    }
    
    file :
    {
      # This selection means in practice that a memory-based contentServer is embedded into the grid-engine.
      # It gets its content information from CSV-files that can be found from the "contentDir". It monitors 
      # the state of these files and automatically updates changes into its memory structures.  Notice that
      # if this content source is selected then there is no need use for the local cache.

      contentDir          = "$(HOME)/Data"
           
      # Size of the event list. If there are no local cache then this size should be 0.
      # Otherwise it should be quite big (1000000 - 5000000) 
    
      eventListMaxSize = 0                   
    }      
    
  }


  ######  The local (caching) content server. 

  cache :
  {
    enabled = true
        
    # Should the get requests be forwarded to the original content source when the cache update is in progress 
    requestForwardEnabled = false
    
    # Fast searches require that content information is sorted. However, it is usually a little bit difficult to update
    # this kind of structure in real-time so that it does not slow down search requests, especially when there are several      
    # updates and hundreds of parallel requests going on at the same time. In this case we should use content swapping.  
    # The idea is that we have two different structures: the first one is used for continious updates and the second one 
    # is used for searches. So the first structure is always up to date and we do not use it for searches. However, we 
    # swap this structure to the search structure time to time (=> contentUpdateInterval). This kind of swapping is 
    # very fast operation and does not cause any significant breaks for searches.
    
    # Notice that the content swapping increases the memory consumtion a little bit. You do not need to use it
    # if your content is not continuously updated.  
           
    contentSwapEnabled = true
    
    contentUpdateInterval = 180       
  }
  
  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/contentServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/contentServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
}



# The data server is responsible for fetching actual data from the grid files. It is possible
# to use a local or a remote data server. The data server uses also a lot of memory and maps
# grid files into virtual memory. That's why it would be smarter to use shared data servers
# when possible. On the other hand, the remote data server is usually always up and running
# which means that it can be used immediately. If the data server is local then it
# takes some time to start the system and make sure that all grid files are available.
# If the remote data server is disabled then the local data server is used in the engine.

data-server :
{
  ######  The remote data server. Notice that the remote data server has its own configuration file.
  
  remote  = false
  caching = false
  ior     = "$(CORBA_DATA_SERVER_IOR)"
   
  ######  The local data server. These settings are valid when the "remote" attribute is "false".

  # Location of grid files.

  grid-storage : 
  {
    directory = "$(GRID_FILE_STORAGE_DIR)"  
    
    # Grid files can be released from the memory if they are not accessed in a given time (= age in seconds). 
    # This feature is useful especially with archive installations that might contains millions of 
    # grids, which are rarely accessed.
    
    clean-up :
    {
      age = 3600
      checkInterval = 300  
    } 
  }
  
  // Startup cache is used for speed up the data loading when the server is started. The idea is
  // that the grid-engine saves the most popular data into the fast disk (maybe M.2 disk)
  // so this data can be loaded quickly back into the memory if the server is restarted.
  // Originally the idea was to store data that was loaded from the network, but it is possible 
  // also to save data that is loaded from the mounted disk. This makes sense if the cache disk 
  // is much faster than the mounted disk.

  startup-cache :
  {
    enabled = false
    saveDiskData = false
    saveNetworkData = true
    filename = "/home/koskelam/Disk/Cache/startup-cache"
    saveIntervalInMinutes = 10
    maxSizeInMegaBytes = 30000
  }

    
  # The data server can generate "virtual grid files" that are based on
  # existing grid files. The definition file is used in order to define
  # requirements (= required parameters) and rules (= LUA function) for 
  # new virtual files.  
       
  virtualFiles :
  {
    enabled = false
    definitionFile = "%(DIR)/vff_convert.csv"
  }
  
  # LUA files are usually needed for generating content for the virtual
  # files. In practice, each virtual file definition contains the name
  # of the LUA function that needs to be called when the data of 
  # the current virtual file is requested.
  
  luaFiles = 
  [
    "%(DIR)/vff_convert.lua"
  ];

  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/dataServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/dataServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
}


# The query server is responsible for making data queries to the data server according
# to the content information that it gets from the content server. Also the query server
# can be local or remote. Sometimes it is smarter to locate the query server closer to 
# the content server and the data server, because there might be a lot traffic between them.
# If the remote query server is disabled then the local query server is used in the engine.

query-server :
{
  remote  = false
  ior     = "$(CORBA_QUERY_SERVER_IOR)"

  # If you want to search data from a certain producer then this producer must be listed in 
  # this file. On the other hand, this file defines the search order of the producers and geometries 
  # in the case of that the producer or the geometry is not defined.  
  
  producerFile = "$(GRID_ENGINE_PRODUCER_FILE)"
  
  
  # If parameter values in different levels (= pressure/hybrid level) needs to be fetched in metric 
  # height requests, then we need a file that defines metric conversions for these levels.   
  
  heightConversionFile = "%(DIR)/height_conversions.csv"
  
  
  # The producer mapping files are used for mapping newbase producers and parameters to the correct
  # grib producers, gemetries and level types. 
  
  producerMappingFiles = 
  [
    "%(DIR)/pm_pal_skandinavia.cfg",
    "%(DIR)/pm_ecmwf_skandinavia_pinta.cfg",
    "%(DIR)/pm_ecmwf_eurooppa_pinta.cfg",
    "%(DIR)/pm_ecmwf_eurooppa_painepinta.cfg",
    "%(DIR)/pm_ecmwf_eurooppa_mallipinta.cfg",
    "%(DIR)/pm_ecmwf_maailma_pinta.cfg",
    "%(DIR)/pm_ecmwf_maailma_painepinta.cfg",
    "%(DIR)/pm_ecmwf_maailma_mallipinta.cfg",
    "%(DIR)/pm_default.cfg"
  ];
   
  producerStatusFile = "%(DIR)/stat_newbase_producers.cfg"  

  
  # Should we check also the geometry status during a query, or is the generation status enough 
  
  checkGeometryStatus = false;
  

  queryCache :
  {
    # A query object is removed from the cache if it accessed in this time (seconds). 
    
    enabled = false
    maxAge = 300
  }
  
  contentCache:
  {  
    maxRecordsPerThread = 10000
    clearInterval = 600
  }
  
  contentSearchCache:
  {  
    maxRecordsPerThread = 100000
    clearInterval = 600
  }
   
  # If the gridEngine notices that there are not valid mappings available for all
  # parameters found from the contentServer, then it automatically adds these unmapped
  # parameters to the following files. The queryServer needs these mappings in order to
  # find the current parameters. You can move these automatically generated mappings into
  # a more permanent mapping file (mappings_fmi_auto.csv => mappings_fmi.csv). On the other
  # hand, when the permanent mapping files are empty then you can get your basic mapping
  # settings from these automatically generated files (i.e. when you are first time 
  # configuring your system).
  
  
  # 1 = FMI_ID, 2 = FMI_NAME, 3 = GRIB_ID, 4 = NEWBASE_ID, 5 = NEWBASE_NAME, 6 = NETCDF_NAME
  
  mappingTargetKeyType = 2 
  
  mappingLevelSimplification = [2,3,4,10,18];
    
  mappingUpdateFile :
  {
    fmi     = "%(DIR)/mapping_fmi_auto.csv"
    newbase = "%(DIR)/mapping_newbase_auto.csv"
    netCdf  = "%(DIR)/mapping_netCdf_auto.csv"
  }
  
  luaFiles = 
  [
    "%(DIR)/function_basic.lua",
    "%(DIR)/function_interpolation.lua",
    "%(DIR)/function_conversion.lua",
    "%(DIR)/function_ensemble.lua",
    "%(DIR)/function_newbase.lua",
    "%(DIR)/function_demo.lua",
    "%(DIR)/function_grid.lua"
  ];
  
  mappingFiles =
  [
    "%(DIR)/mapping_fmi.csv",
    "%(DIR)/mapping_fmi_auto.csv",
    "%(DIR)/mapping_newbase.csv",
    "%(DIR)/mapping_newbase_auto.csv",
    "%(DIR)/mapping_netCdf.csv",
    "%(DIR)/mapping_netCdf_auto.csv",
    "%(DIR)/mapping_virtual.csv"
  ];

  aliasFiles =
  [
    "%(DIR)/alias_demo.cfg",
    "%(DIR)/alias_newbase_extension.cfg"
  ];

  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/queryServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/queryServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
}


# smartmet-plugin-grid-admin can browse information in the grid engine. 

browser :
{
  enabled  = true
  
  # This field is used for defining permissions for the browsing. Permissions are
  # expressed with bits (0 = disabled, 1 = enabled)
  # 
  #   bit 0 : Content modification
  #   bit 1 : Log modification
  
  flags    = 3
}

}
}
}
