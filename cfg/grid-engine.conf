################################################################## 
# smartmet-engine-grid
################################################################## 

# This is a configuration file used by the module
# smartmet-engine-grid. The SmartMet server's configuration
# file for the "grid" engine should point to this file.

##################################################################



# Importing global configuration parameters. There should be
# an environment variable SMARTMET_ENV_FILE that points to
# the global configuration file. The idea is that you can easily
# change your environment by editing this file. 

@ifdef SMARTMET_ENV_FILE
  @include "$(SMARTMET_ENV_FILE)"
@else
  @print "The environment variable 'SMARTMET_ENV_FILE' not defined!" @location
  @include "$(HOME)/workspace/smartmet-tools-grid/cfg/smartmet-dev-env.cfg"
@endif


smartmet :
{
library :
{

grid-files :
{
  # Processing of grid/grib files requires a lot of configuration information. 
  # This information should be found from the file below. 

  configFile = "$(GRID_FILES_LIBRARY_CONFIG_FILE)"
  
  # Are we using our own memoryMapper implementation. If "premapEnabled" is "true" then
  # the whole grid is preloaded when it is first time accessed. Otherwise only the requested
  # memory page is mapped. The point is that we can load data in small pieces when it requsted
  # or bigger pieces so that the number of the download requests will be smaller. 
  
  memoryMapper :
  {
    enabled = false
    accessFile = "%(DIR)/access.csv"
    premapEnabled = true
    maxProsessingThreads = 30
    maxMessages = 100000
    pageCacheSize = 2000000
    fileHandleLimit = 10000    
  }

  # If the data server is local then the grid file cache can be used to improve
  # performance. This cache is used caching uncompressed grid data. When the cache 
  # is full then the oldest data is automatically removed. The cache type can be
  # "memory" or "filesys". If the type is "filesys" then cached grids are stored
  # into files and these files are memory mapped. 
    
  cache :
  {
    type                = "filesys"
    directory           = "$(HOME)/Var/Cache/Uncompressed"
    numOfGrids          = 50000
    maxSizeInMegaBytes  = 30000   
  }
}

} # library


engine :
{
grid :
{

  # The usage of the grid-engine can be enabled/disabled
  
  enabled = true

# The content server defines the source of the content information. Usually the master 
# content source is the Redis database. However,it can be also a memory-based content
# server or a caching content server, which are accessed by HTTP or CORBA.

# The Redis database is not usually fast enough for our searching purposes. That's why 
# its information is usally cached locally into the memory. In this case the content 
# information can be sorted so that it can be fetched very fast. In spite of that we
# can sort the current content information in many ways, we should not sort it all
# possible ways because this increases the memory consumtion and it also makes content
# updates slower. In practice, we should select the main content identifiers and sort
# the content information according to them. All the other information should be mapped
# to those identifiers when querying content information.

# If the content source itself is a caching content server then there is usually no need to 
# locally cache the same information. Caching content information makes content searching very 
# fast but it might required a lot of memory. That's why it usually makes sense to use a remote 
# caching server if that is possible. On the other hand this means that the grid engine can start 
# much faster because it does not need to cache content information first.

content-server :
{
    
  content-source : 
  {
    # Content source type (redis/corba/http/file/postgresql)

    type = "redis"

    redis :
    {
      address          = "$(REDIS_CONTENT_SERVER_PRIMARY_ADDRESS)"
      port             = $(REDIS_CONTENT_SERVER_PRIMARY_PORT)
      tablePrefix      = "$(REDIS_CONTENT_SERVER_TABLE_PREFIX)"
      secondaryAddress = "$(REDIS_CONTENT_SERVER_SECONDARY_ADDRESS)"
      secondaryPort    = $(REDIS_CONTENT_SERVER_SECONDARY_PORT)
      lockEnabled      = false;
      reloadRequired   = false;
    }

    
    postgresql :
    {
      primaryConnectionString = "$(PG_CONTENT_SERVER_PRIMARY_CONNECTION_STRING)"
      secondaryConnectionString = "$(PG_CONTENT_SERVER_SECONDARY_CONNECTION_STRING)"
    }    
    
    corba :
    {
      ior          = "$(CORBA_CONTENT_SERVER_IOR)"
    }


    http :
    {
      url          = "$(HTTP_CONTENT_SERVER_URL)"
    }
    
    file :
    {
      # This selection means in practice that a memory-based contentServer is embedded into the grid-engine.
      # It gets its content information from CSV-files that can be found from the "contentDir". It monitors 
      # the state of these files and automatically updates changes into its memory structures.  Notice that
      # if this content source is selected then there is no need use for the local cache.

      contentDir          = "$(HOME)/Data"
           
      # Size of the event list. If there are no local cache then this size should be 0.
      # Otherwise it should be quite big (1000000 - 5000000) 
    
      eventListMaxSize = 0                   
    }      
    
  }


  ######  The local (caching) content server. 

  cache :
  {
    enabled = true
        
    # Should the get requests be forwarded to the original content source when the cache update is in progress 
    
    requestForwardEnabled = false
    
    # Fast searches require that content information is sorted. However, it is usually a little bit difficult to update
    # this kind of structure in real-time so that it does not slow down search requests, especially when there are several      
    # updates and hundreds of parallel requests going on at the same time. In this case we should use content swapping.  
    # The idea is that we have two different structures: the first one is used for continious updates and the second one 
    # is used for searches. So the first structure is always up to date and we do not use it for searches. However, we 
    # swap this structure to the search structure time to time (=> contentUpdateInterval). This kind of swapping is 
    # very fast operation and does not cause any significant breaks for searches.
    
    # Notice that the content swapping increases the memory consumtion a little bit. You do not need to use it
    # if your content is not continuously updated.  
           
    contentSwapEnabled = true
    contentUpdateInterval = 180       

	# If the dataServer is caching grid files into the local filesystem, we should define how long time the content server
	# can delay the content swapping when it waits that all required files are cached locally. If the wait time is zero 
	# second then the swapping does not wait that the local cache gets ready. This only means that if a file is not in 
	# the local cache when it is requested, then the data server uses the original grid file instead. On the other hand,
	# if the content server is waiting the local cache, we should make sure that it does not wait if forever. That's 
	# because the local caching might also face some problems (for example, the local filesystem can be full). It is also
	# quite common that if the local cache is empty when the server is started and if there are a lot of data that requires
	# caching, then the first wait time should be longer. That's why we have two different wait times. 
	
    fileCache :
    {
      maxFirstWaitTime    = 0     
      maxWaitTime         = 0
    }     
  }
  
  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/contentServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/contentServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
}



# The data server is responsible for fetching actual data from the grid files. It is possible
# to use a local or a remote data server. The data server uses also a lot of memory and maps
# grid files into virtual memory. That's why it would be smarter to use shared data servers
# when possible. On the other hand, the remote data server is usually always up and running
# which means that it can be used immediately. If the data server is local then it
# takes some time to start the system and make sure that all grid files are available.
# If the remote data server is disabled then the local data server is used in the engine.

data-server :
{
  ######  The remote data server. Notice that the remote data server has its own configuration file.
  
  remote  = false
  ior     = "$(CORBA_DATA_SERVER_IOR)"
   
  ######  The local data server. These settings are valid when the "remote" attribute is "false".

  # Location of grid files.

  grid-storage : 
  {
    directory = "$(GRID_FILE_STORAGE_DIR)"  
    
    # Grid files can be released from the memory if they are not accessed in a given time (= age in seconds). 
    # This feature is useful especially with archive installations that might contains millions of 
    # grids, which are rarely accessed.
    
    clean-up :
    {
      age = 3600
      checkInterval = 600  
    } 
  }
  
  # Local file cache is used in order to store some marked grid files locally before they can be taken 
  # into use. The actual marking of the files is done by the 'radon2smartmet' program, which stores this 
  # information into the FileInfo -records when it writes this informatin into the Content Storage.
  # The idea is to cache frequently accessed files into the local filesystem, which helps to reduce network 
  # traffic. Notice that the following configuration lines enable local file caching in the dataServer. If 
  # you want that all marked files are stored locally before they are taken in to used, then you should define 
  # how long time the contentServer is allowed wait this local file caching (=> see contentServer "fileCache" 
  # definitions above). 

  fileCache :
  {
    enabled   = false
    directory = "$(HOME)/Var/Cache"
  }
   
  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/dataServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/dataServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
}


# The query server is responsible for making data queries to the data server according
# to the content information that it gets from the content server. Also the query server
# can be local or remote. Sometimes it is smarter to locate the query server closer to 
# the content server and the data server, because there might be a lot traffic between them.
# If the remote query server is disabled then the local query server is used in the engine.

query-server :
{
  remote  = false
  ior     = "$(CORBA_QUERY_SERVER_IOR)"

  # If you want to search data from a certain producer then this producer must be listed in 
  # this file. On the other hand, this file defines the search order of the producers and geometries 
  # in the case of that the producer or the geometry is not defined.  
  
  producerFile = "%(DIR)/producers.csv"
  
  
  # If parameter values in different levels (= pressure/hybrid level) needs to be fetched in metric 
  # height requests, then we need a file that defines metric conversions for these levels.   
  
  heightConversionFile = "%(DIR)/height_conversions.csv"
  
  #################### NEWBASE SPECIFIC DEFINITIONS ################################################
  
  # The producer mapping files are used for mapping newbase producers and parameters to the correct
  # grib producers, gemetries and level types. 
  
  producerMappingFiles = 
  [
    "%(DIR)/newbase/pm_pal_skandinavia.cfg",
    "%(DIR)/newbase/pm_ecmwf_eurooppa_pinta.cfg",
    "%(DIR)/newbase/pm_ecmwf_eurooppa_painepinta.cfg",
    "%(DIR)/newbase/pm_ecmwf_eurooppa_mallipinta.cfg",
    "%(DIR)/newbase/pm_ecmwf_maailma_pinta.cfg",
    "%(DIR)/newbase/pm_ecmwf_maailma_painepinta.cfg",
    "%(DIR)/newbase/pm_ecmwf_maailma_mallipinta.cfg",
    "%(DIR)/newbase/pm_default.cfg"
  ];
   
  producerStatusFile = "%(DIR)/newbase/stat_newbase_producers.cfg"  

  ##################################################################################################

  # Usually we can query only such generations which status is marked to be ready. In addition we
  # can define if we can query data from the geometries which status is not marked to be ready. 
  # It is quite common that we do not care about this status, because it is not necessary defined 
  # in the original data source. 
  
  checkGeometryStatus = false;
  

  # The query cache can be used if the same queries are repeated multiple times during a short
  # period of time. However, it is quite common that there are already some other caches (like frontend) 
  # in place. In this case the cache should be turned off, because it is just a waste of resources
  # to cache queries that are not repeated continuously.

  queryCache :
  {
    # A query object is removed from the cache if it accessed in this time (seconds). 
    
    enabled = false
    maxAge = 300
  }
  
  contentCache:
  {  
    maxRecordsPerThread = 10000
    clearInterval = 600
  }
  
  contentSearchCache:
  {  
    maxRecordsPerThread = 100000
    clearInterval = 600
  }
   
  # If the gridEngine notices that there are not valid mappings available for all
  # parameters found from the contentServer, then it automatically adds these unmapped
  # parameters to the following files. The queryServer needs these mappings in order to
  # find the current parameters. You can move these automatically generated mappings into
  # a more permanent mapping file (mappings_fmi_auto.csv => mappings_fmi.csv). On the other
  # hand, when the permanent mapping files are empty then you can get your basic mapping
  # settings from these automatically generated files (i.e. when you are first time 
  # configuring your system).
  
  
  # 1 = FMI_ID, 2 = FMI_NAME, 3 = GRIB_ID, 4 = NEWBASE_ID, 5 = NEWBASE_NAME, 6 = NETCDF_NAME
  
  mappingTargetKeyType = 2 
  
  mappingLevelSimplification = [2,3,4,10,18];
    
  mappingUpdateFile :
  {
    fmi     = "%(DIR)/parameter/mapping_fmi_auto.csv"
    newbase = "%(DIR)/parameter/mapping_newbase_auto.csv"
    netCdf  = "%(DIR)/parameter/mapping_netCdf_auto.csv"
  }
  
  luaFiles = 
  [
    "%(DIR)/lua/function_basic.lua",
    "%(DIR)/lua/function_interpolation.lua",
    "%(DIR)/lua/function_conversion.lua",
    "%(DIR)/lua/function_ensemble.lua",
    "%(DIR)/lua/function_newbase.lua",
    "%(DIR)/lua/function_demo.lua"
#    "%(DIR)/lua/function_grid.lua"
  ];
  
  mappingFiles =
  [
    "%(DIR)/parameter/mapping_fmi.csv",
    "%(DIR)/parameter/mapping_fmi_auto.csv",
    "%(DIR)/parameter/mapping_newbase.csv",
    "%(DIR)/parameter/mapping_newbase_auto.csv",
    "%(DIR)/parameter/mapping_netCdf.csv",
    "%(DIR)/parameter/mapping_netCdf_auto.csv"
  ];


  # The list of files that are use for generating build-in mapping aliases based on unit conversions.
  # The idea is that if a parameter name contains an unit name (for example "T-K") then we can 
  # use the unit conversion file in order to generate build-in parameter mappings that use different
  # units (for example "T-K" => "T-C"). Notice that these build-in mappings are generated when the server
  # starts. 
  
  mappingAliasFiles =
  [
    "%(DIR)/parameter/mapping_fmi.csv"
  ];

  unitConversionFile = "%(DIR)/unitConversions.csv"
  


  # Parameter name/function alias files. Usually parameter name aliases are defined by using
  # mapping files. If a parameter is function with parameters then we might want to define
  # an alias name for this function call.

  aliasFiles =
  [
    "%(DIR)/alias/alias_demo.cfg",
    "%(DIR)/alias/alias_newbase_extension.cfg"
  ];

  processing-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/queryServer_processing.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
  
  debug-log :
  {
    enabled      = false
    file         = "$(GRID_ENGINE_LOG_DIR)/queryServer_debug.log"
    maxSize      = 100000000
    truncateSize = 20000000
  }
}


# smartmet-plugin-grid-admin can browse information in the grid engine. 

browser :
{
  enabled  = true
  
  # This field is used for defining permissions for the browsing. Permissions are
  # expressed with bits (0 = disabled, 1 = enabled)
  # 
  #   bit 0 : Content modification
  #   bit 1 : Log modification
  
  flags    = 3
}

}
}
}
